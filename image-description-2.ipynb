{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1111749,"sourceType":"datasetVersion","datasetId":623329,"isSourceIdPinned":false}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers accelerate timm datasets -q\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BlipProcessor, BlipForConditionalGeneration\nfrom PIL import Image\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T21:33:03.828717Z","iopub.execute_input":"2025-09-05T21:33:03.829055Z","iopub.status.idle":"2025-09-05T21:33:09.188720Z","shell.execute_reply.started":"2025-09-05T21:33:03.829030Z","shell.execute_reply":"2025-09-05T21:33:09.187207Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# 2. DEVICE CONFIG\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using device:\", DEVICE)\n\ntorch.backends.cudnn.enabled = True\ntorch.backends.cudnn.benchmark = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T21:33:51.479279Z","iopub.execute_input":"2025-09-05T21:33:51.479765Z","iopub.status.idle":"2025-09-05T21:33:51.487372Z","shell.execute_reply.started":"2025-09-05T21:33:51.479716Z","shell.execute_reply":"2025-09-05T21:33:51.486008Z"}},"outputs":[{"name":"stdout","text":"Using device: cpu\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# 3. PATHS (HARDCODED)\n\nIMAGES_PATH = \"/kaggle/input/flickr30k/Images\"\nCAPTIONS_FILE = \"/kaggle/input/flickr30k/captions.txt\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T21:34:47.765504Z","iopub.execute_input":"2025-09-05T21:34:47.765872Z","iopub.status.idle":"2025-09-05T21:34:47.771832Z","shell.execute_reply.started":"2025-09-05T21:34:47.765848Z","shell.execute_reply":"2025-09-05T21:34:47.770585Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# 4. LOAD DATASET\n\ndf = pd.read_csv(CAPTIONS_FILE)\ndf.columns = ['image', 'caption']  # Ensure only two columns: image, caption\nprint(\"Sample data:\")\nprint(df.head())\n\n# Split into Train (90%) and Validation (10%)\ntrain_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T21:37:46.527762Z","iopub.execute_input":"2025-09-05T21:37:46.528136Z","iopub.status.idle":"2025-09-05T21:37:46.893403Z","shell.execute_reply.started":"2025-09-05T21:37:46.528111Z","shell.execute_reply":"2025-09-05T21:37:46.892488Z"}},"outputs":[{"name":"stdout","text":"Sample data:\n            image                                            caption\n0  1000092795.jpg   Two young guys with shaggy hair look at their...\n1  1000092795.jpg   Two young , White males are outside near many...\n2  1000092795.jpg   Two men in green shirts are standing in a yard .\n3  1000092795.jpg       A man in a blue shirt standing in a garden .\n4  1000092795.jpg            Two friends enjoy time spent together .\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# 5. DATASET CLASS\n\nclass Flickr30kDataset(Dataset):\n    def __init__(self, dataframe, image_path, processor):\n        self.dataframe = dataframe\n        self.image_path = image_path\n        self.processor = processor\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        row = self.dataframe.iloc[idx]\n        image_file = os.path.join(self.image_path, row['image'])\n        image = Image.open(image_file).convert('RGB')\n        caption = row['caption']\n\n        inputs = self.processor(\n            images=image,\n            text=caption,\n            return_tensors=\"pt\",\n            padding=\"max_length\",\n            max_length=30,\n            truncation=True\n        )\n        return {\n            \"pixel_values\": inputs[\"pixel_values\"].squeeze(),\n            \"input_ids\": inputs[\"input_ids\"].squeeze(),\n            \"attention_mask\": inputs[\"attention_mask\"].squeeze()\n        }\n\n# 6. INIT PROCESSOR & MODEL\n\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\nmodel = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\nmodel = model.to(DEVICE)\n\n# 7. CREATE DATASETS & DATALOADERS\n\ntrain_dataset = Flickr30kDataset(train_df, IMAGES_PATH, processor)\nval_dataset = Flickr30kDataset(val_df, IMAGES_PATH, processor)\n\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2, pin_memory=True)\n\n# 8. TRAINING SETUP\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\nscaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\")) \n\nepochs = 3 \nbest_val_loss = float(\"inf\")\n\n\n# 9. TRAINING + VALIDATION LOOP\n\ndef evaluate(model, val_loader):\n    model.eval()\n    total_loss = 0\n    with torch.no_grad():\n        for batch in val_loader:\n            pixel_values = batch[\"pixel_values\"].to(DEVICE)\n            input_ids = batch[\"input_ids\"].to(DEVICE)\n            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n\n            outputs = model(\n                pixel_values=pixel_values,\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=input_ids\n            )\n            total_loss += outputs.loss.item()\n    return total_loss / len(val_loader)\n\nfor epoch in range(epochs):\n    model.train()\n    running_loss = 0\n    loop = tqdm(train_loader, leave=True)\n    \n    for batch in loop:\n        pixel_values = batch[\"pixel_values\"].to(DEVICE)\n        input_ids = batch[\"input_ids\"].to(DEVICE)\n        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n\n        with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n            outputs = model(\n                pixel_values=pixel_values,\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=input_ids\n            )\n            loss = outputs.loss\n\n        optimizer.zero_grad()\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        running_loss += loss.item()\n        loop.set_description(f\"Epoch [{epoch+1}/{epochs}]\")\n        loop.set_postfix(train_loss=loss.item())\n\n    avg_train_loss = running_loss / len(train_loader)\n    val_loss = evaluate(model, val_loader)\n\n    print(f\"\\nEpoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n\n    # Save best model\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        model.save_pretrained(\"/kaggle/working/blip-flickr30k-best\")\n        processor.save_pretrained(\"/kaggle/working/blip-flickr30k-best\")\n        print(\"âœ… Saved Best Model!\")\n\n\n# 10. FINAL SAVE MODEL\n\nmodel.save_pretrained(\"/kaggle/working/blip-flickr30k-final\")\nprocessor.save_pretrained(\"/kaggle/working/blip-flickr30k-final\")\nprint(\"Final Model saved!\")\n\n\n# 11. INFERENCE (Caption Generation)\n\nmodel.eval()\ntest_image_path = os.path.join(IMAGES_PATH, df.iloc[0]['image'])\ntest_image = Image.open(test_image_path).convert('RGB')\n\ninputs = processor(images=test_image, return_tensors=\"pt\").to(DEVICE)\n\nwith torch.no_grad():\n    generated_ids = model.generate(**inputs, max_length=30)\n    caption = processor.decode(generated_ids[0], skip_special_tokens=True)\n\nprint(\"Generated Caption:\", caption)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T21:40:36.148709Z","iopub.execute_input":"2025-09-05T21:40:36.149133Z"}},"outputs":[{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a50da5e46cb4212b02c79c42b28e190"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/506 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29e162738a75426097e01d9ff1fd9840"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5dd41ff0d8346a7b926c3b1aeccbd79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa3801e1fb6d45938f97e22a15a9fe86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"135fe746f88c48aea75b23f75ba1ac3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e53424b94b2453f991890e08a013e48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1516cbcb306a4511b4e552e383028449"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b1ab571a1334f0490cc11e7d48ce944"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/162859600.py:50: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))  # Mixed precision only if GPU\n\n  0%|          | 0/17878 [00:00<?, ?it/s]\u001b[A/tmp/ipykernel_36/162859600.py:86: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n\nEpoch [1/3]:   0%|          | 0/17878 [00:54<?, ?it/s]\u001b[A\nEpoch [1/3]:   0%|          | 0/17878 [00:54<?, ?it/s, train_loss=8.17]\u001b[A\nEpoch [1/3]:   0%|          | 1/17878 [00:54<269:59:40, 54.37s/it, train_loss=8.17]\u001b[A\nEpoch [1/3]:   0%|          | 1/17878 [01:35<269:59:40, 54.37s/it, train_loss=8.17]\u001b[A\nEpoch [1/3]:   0%|          | 1/17878 [01:35<269:59:40, 54.37s/it, train_loss=7]   \u001b[A\nEpoch [1/3]:   0%|          | 2/17878 [01:35<230:58:39, 46.52s/it, train_loss=7]\u001b[A\nEpoch [1/3]:   0%|          | 2/17878 [02:11<230:58:39, 46.52s/it, train_loss=7]\u001b[A\nEpoch [1/3]:   0%|          | 2/17878 [02:11<230:58:39, 46.52s/it, train_loss=7.71]\u001b[A\nEpoch [1/3]:   0%|          | 3/17878 [02:11<208:28:23, 41.99s/it, train_loss=7.71]\u001b[A\nEpoch [1/3]:   0%|          | 3/17878 [02:47<208:28:23, 41.99s/it, train_loss=7.71]\u001b[A\nEpoch [1/3]:   0%|          | 3/17878 [02:47<208:28:23, 41.99s/it, train_loss=6.86]\u001b[A\nEpoch [1/3]:   0%|          | 4/17878 [02:47<195:17:49, 39.33s/it, train_loss=6.86]\u001b[A\nEpoch [1/3]:   0%|          | 4/17878 [03:20<195:17:49, 39.33s/it, train_loss=6.86]\u001b[A\nEpoch [1/3]:   0%|          | 4/17878 [03:20<195:17:49, 39.33s/it, train_loss=6.28]\u001b[A\nEpoch [1/3]:   0%|          | 5/17878 [03:20<184:22:20, 37.14s/it, train_loss=6.28]\u001b[A\nEpoch [1/3]:   0%|          | 5/17878 [03:52<184:22:20, 37.14s/it, train_loss=6.28]\u001b[A\nEpoch [1/3]:   0%|          | 5/17878 [03:52<184:22:20, 37.14s/it, train_loss=6.5] \u001b[A\nEpoch [1/3]:   0%|          | 6/17878 [03:52<176:25:54, 35.54s/it, train_loss=6.5]\u001b[A\nEpoch [1/3]:   0%|          | 6/17878 [04:26<176:25:54, 35.54s/it, train_loss=6.5]\u001b[A\nEpoch [1/3]:   0%|          | 6/17878 [04:26<176:25:54, 35.54s/it, train_loss=6.4]\u001b[A\nEpoch [1/3]:   0%|          | 7/17878 [04:26<173:39:54, 34.98s/it, train_loss=6.4]\u001b[A\nEpoch [1/3]:   0%|          | 7/17878 [04:59<173:39:54, 34.98s/it, train_loss=6.4]\u001b[A\nEpoch [1/3]:   0%|          | 7/17878 [04:59<173:39:54, 34.98s/it, train_loss=6.7]\u001b[A\nEpoch [1/3]:   0%|          | 8/17878 [04:59<170:31:31, 34.35s/it, train_loss=6.7]\u001b[A\nEpoch [1/3]:   0%|          | 8/17878 [05:32<170:31:31, 34.35s/it, train_loss=6.7]\u001b[A\nEpoch [1/3]:   0%|          | 8/17878 [05:32<170:31:31, 34.35s/it, train_loss=5.75]\u001b[A\nEpoch [1/3]:   0%|          | 9/17878 [05:32<168:21:17, 33.92s/it, train_loss=5.75]\u001b[A\nEpoch [1/3]:   0%|          | 9/17878 [06:06<168:21:17, 33.92s/it, train_loss=5.75]\u001b[A\nEpoch [1/3]:   0%|          | 9/17878 [06:06<168:21:17, 33.92s/it, train_loss=6.03]\u001b[A\nEpoch [1/3]:   0%|          | 10/17878 [06:06<168:19:44, 33.91s/it, train_loss=6.03]\u001b[A\nEpoch [1/3]:   0%|          | 10/17878 [06:40<168:19:44, 33.91s/it, train_loss=6.03]\u001b[A\nEpoch [1/3]:   0%|          | 10/17878 [06:40<168:19:44, 33.91s/it, train_loss=5.84]\u001b[A\nEpoch [1/3]:   0%|          | 11/17878 [06:40<167:35:20, 33.77s/it, train_loss=5.84]\u001b[A\nEpoch [1/3]:   0%|          | 11/17878 [07:12<167:35:20, 33.77s/it, train_loss=5.84]\u001b[A\nEpoch [1/3]:   0%|          | 11/17878 [07:12<167:35:20, 33.77s/it, train_loss=5.7] \u001b[A\nEpoch [1/3]:   0%|          | 12/17878 [07:12<165:16:27, 33.30s/it, train_loss=5.7]\u001b[A\nEpoch [1/3]:   0%|          | 12/17878 [07:44<165:16:27, 33.30s/it, train_loss=5.7]\u001b[A\nEpoch [1/3]:   0%|          | 12/17878 [07:44<165:16:27, 33.30s/it, train_loss=5]  \u001b[A\nEpoch [1/3]:   0%|          | 13/17878 [07:44<163:17:00, 32.90s/it, train_loss=5]\u001b[A\nEpoch [1/3]:   0%|          | 13/17878 [08:16<163:17:00, 32.90s/it, train_loss=5]\u001b[A\nEpoch [1/3]:   0%|          | 13/17878 [08:16<163:17:00, 32.90s/it, train_loss=5.24]\u001b[A\nEpoch [1/3]:   0%|          | 14/17878 [08:16<162:03:29, 32.66s/it, train_loss=5.24]\u001b[A\nEpoch [1/3]:   0%|          | 14/17878 [08:48<162:03:29, 32.66s/it, train_loss=5.24]\u001b[A\nEpoch [1/3]:   0%|          | 14/17878 [08:48<162:03:29, 32.66s/it, train_loss=5.52]\u001b[A\nEpoch [1/3]:   0%|          | 15/17878 [08:48<161:13:17, 32.49s/it, train_loss=5.52]\u001b[A\nEpoch [1/3]:   0%|          | 15/17878 [09:29<161:13:17, 32.49s/it, train_loss=5.52]\u001b[A\nEpoch [1/3]:   0%|          | 15/17878 [09:29<161:13:17, 32.49s/it, train_loss=5.31]\u001b[A\nEpoch [1/3]:   0%|          | 16/17878 [09:29<173:24:09, 34.95s/it, train_loss=5.31]\u001b[A\nEpoch [1/3]:   0%|          | 16/17878 [10:04<173:24:09, 34.95s/it, train_loss=5.31]\u001b[A\nEpoch [1/3]:   0%|          | 16/17878 [10:04<173:24:09, 34.95s/it, train_loss=4.8] \u001b[A\nEpoch [1/3]:   0%|          | 17/17878 [10:04<174:22:23, 35.15s/it, train_loss=4.8]\u001b[A\nEpoch [1/3]:   0%|          | 17/17878 [10:37<174:22:23, 35.15s/it, train_loss=4.8]\u001b[A\nEpoch [1/3]:   0%|          | 17/17878 [10:37<174:22:23, 35.15s/it, train_loss=5.4]\u001b[A\nEpoch [1/3]:   0%|          | 18/17878 [10:37<171:19:04, 34.53s/it, train_loss=5.4]\u001b[A\nEpoch [1/3]:   0%|          | 18/17878 [11:11<171:19:04, 34.53s/it, train_loss=5.4]\u001b[A\nEpoch [1/3]:   0%|          | 18/17878 [11:11<171:19:04, 34.53s/it, train_loss=4.98]\u001b[A\nEpoch [1/3]:   0%|          | 19/17878 [11:11<170:37:57, 34.40s/it, train_loss=4.98]\u001b[A\nEpoch [1/3]:   0%|          | 19/17878 [11:44<170:37:57, 34.40s/it, train_loss=4.98]\u001b[A\nEpoch [1/3]:   0%|          | 19/17878 [11:44<170:37:57, 34.40s/it, train_loss=4.86]\u001b[A\nEpoch [1/3]:   0%|          | 20/17878 [11:44<168:16:16, 33.92s/it, train_loss=4.86]\u001b[A\nEpoch [1/3]:   0%|          | 20/17878 [12:17<168:16:16, 33.92s/it, train_loss=4.86]\u001b[A\nEpoch [1/3]:   0%|          | 20/17878 [12:17<168:16:16, 33.92s/it, train_loss=5.15]\u001b[A\nEpoch [1/3]:   0%|          | 21/17878 [12:17<166:18:24, 33.53s/it, train_loss=5.15]\u001b[A\nEpoch [1/3]:   0%|          | 21/17878 [12:52<166:18:24, 33.53s/it, train_loss=5.15]\u001b[A\nEpoch [1/3]:   0%|          | 21/17878 [12:52<166:18:24, 33.53s/it, train_loss=5.34]\u001b[A\nEpoch [1/3]:   0%|          | 22/17878 [12:52<168:14:38, 33.92s/it, train_loss=5.34]\u001b[A\nEpoch [1/3]:   0%|          | 22/17878 [13:27<168:14:38, 33.92s/it, train_loss=5.34]\u001b[A\nEpoch [1/3]:   0%|          | 22/17878 [13:27<168:14:38, 33.92s/it, train_loss=5.13]\u001b[A\nEpoch [1/3]:   0%|          | 23/17878 [13:27<169:53:15, 34.25s/it, train_loss=5.13]\u001b[A\nEpoch [1/3]:   0%|          | 23/17878 [14:00<169:53:15, 34.25s/it, train_loss=5.13]\u001b[A\nEpoch [1/3]:   0%|          | 23/17878 [14:00<169:53:15, 34.25s/it, train_loss=4.74]\u001b[A\nEpoch [1/3]:   0%|          | 24/17878 [14:00<168:45:22, 34.03s/it, train_loss=4.74]\u001b[A\nEpoch [1/3]:   0%|          | 24/17878 [14:35<168:45:22, 34.03s/it, train_loss=4.74]\u001b[A\nEpoch [1/3]:   0%|          | 24/17878 [14:35<168:45:22, 34.03s/it, train_loss=4.51]\u001b[A\nEpoch [1/3]:   0%|          | 25/17878 [14:35<169:12:28, 34.12s/it, train_loss=4.51]\u001b[A\nEpoch [1/3]:   0%|          | 25/17878 [15:10<169:12:28, 34.12s/it, train_loss=4.51]\u001b[A\nEpoch [1/3]:   0%|          | 25/17878 [15:10<169:12:28, 34.12s/it, train_loss=4.85]\u001b[A\nEpoch [1/3]:   0%|          | 26/17878 [15:10<170:26:11, 34.37s/it, train_loss=4.85]\u001b[A\nEpoch [1/3]:   0%|          | 26/17878 [15:44<170:26:11, 34.37s/it, train_loss=4.85]\u001b[A\nEpoch [1/3]:   0%|          | 26/17878 [15:44<170:26:11, 34.37s/it, train_loss=4.49]\u001b[A\nEpoch [1/3]:   0%|          | 27/17878 [15:44<171:10:44, 34.52s/it, train_loss=4.49]\u001b[A\nEpoch [1/3]:   0%|          | 27/17878 [16:20<171:10:44, 34.52s/it, train_loss=4.49]\u001b[A\nEpoch [1/3]:   0%|          | 27/17878 [16:20<171:10:44, 34.52s/it, train_loss=4.63]\u001b[A\nEpoch [1/3]:   0%|          | 28/17878 [16:20<172:53:15, 34.87s/it, train_loss=4.63]\u001b[A\nEpoch [1/3]:   0%|          | 28/17878 [16:56<172:53:15, 34.87s/it, train_loss=4.63]\u001b[A\nEpoch [1/3]:   0%|          | 28/17878 [16:56<172:53:15, 34.87s/it, train_loss=4.67]\u001b[A\nEpoch [1/3]:   0%|          | 29/17878 [16:56<174:19:32, 35.16s/it, train_loss=4.67]\u001b[A\nEpoch [1/3]:   0%|          | 29/17878 [17:31<174:19:32, 35.16s/it, train_loss=4.67]\u001b[A\nEpoch [1/3]:   0%|          | 29/17878 [17:31<174:19:32, 35.16s/it, train_loss=4.63]\u001b[A\nEpoch [1/3]:   0%|          | 30/17878 [17:31<173:53:34, 35.07s/it, train_loss=4.63]\u001b[A\nEpoch [1/3]:   0%|          | 30/17878 [18:05<173:53:34, 35.07s/it, train_loss=4.63]\u001b[A\nEpoch [1/3]:   0%|          | 30/17878 [18:05<173:53:34, 35.07s/it, train_loss=4.05]\u001b[A\nEpoch [1/3]:   0%|          | 31/17878 [18:05<172:53:56, 34.88s/it, train_loss=4.05]\u001b[A\nEpoch [1/3]:   0%|          | 31/17878 [18:40<172:53:56, 34.88s/it, train_loss=4.05]\u001b[A\nEpoch [1/3]:   0%|          | 31/17878 [18:40<172:53:56, 34.88s/it, train_loss=4.05]\u001b[A\nEpoch [1/3]:   0%|          | 32/17878 [18:40<173:19:49, 34.97s/it, train_loss=4.05]\u001b[A\nEpoch [1/3]:   0%|          | 32/17878 [19:15<173:19:49, 34.97s/it, train_loss=4.05]\u001b[A\nEpoch [1/3]:   0%|          | 32/17878 [19:15<173:19:49, 34.97s/it, train_loss=4.13]\u001b[A\nEpoch [1/3]:   0%|          | 33/17878 [19:15<173:24:49, 34.98s/it, train_loss=4.13]\u001b[A","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"!ls\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T10:16:18.222934Z","iopub.execute_input":"2025-08-26T10:16:18.223292Z","iopub.status.idle":"2025-08-26T10:16:18.364935Z","shell.execute_reply.started":"2025-08-26T10:16:18.223263Z","shell.execute_reply":"2025-08-26T10:16:18.363729Z"}},"outputs":[],"execution_count":13}]}