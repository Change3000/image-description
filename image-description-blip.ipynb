{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1111749,"sourceType":"datasetVersion","datasetId":623329},{"sourceId":12909641,"sourceType":"datasetVersion","datasetId":8168533}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# blip_kaggle_train_infer_fixed.py\n# pip install -q transformers timm sentencepiece accelerate\n\n#import os\n#import random\n#from pathlib import Path\n#from collections import defaultdict\n\n#import pandas as pd\n#from PIL import Image\n\n#import torch\n#from torch.utils.data import Dataset, DataLoader\n#from torch.optim import AdamW\n#from transformers import BlipProcessor, BlipForConditionalGeneration, get_linear_schedule_with_warmup\n#from torch.cuda.amp import GradScaler, autocast\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T22:48:24.486895Z","iopub.execute_input":"2025-08-29T22:48:24.488197Z","iopub.status.idle":"2025-08-29T22:48:24.495567Z","shell.execute_reply.started":"2025-08-29T22:48:24.488154Z","shell.execute_reply":"2025-08-29T22:48:24.494217Z"},"editable":false},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# 1. INSTALL & IMPORT\n!pip install transformers accelerate timm datasets -q\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BlipProcessor, BlipForConditionalGeneration\nfrom PIL import Image\nimport pandas as pd\nimport os\nfrom tqdm import tqdm","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. DEVICE CONFIG\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using device:\", DEVICE)\n\ntorch.backends.cudnn.enabled = True\ntorch.backends.cudnn.benchmark = True","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. PATHS (HARDCODED)\n\nIMAGES_PATH = \"/kaggle/input/flickr30k/Images\"\nCAPTIONS_FILE = \"/kaggle/input/flickr30k/captions.txt\"\n\n# 4. LOAD DATASET\n\ndf = pd.read_csv(CAPTIONS_FILE)\ndf.columns = ['image', 'caption']  # only 2 columns\n\nprint(\"Sample data:\")\nprint(df.head())","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5. DATASET CLASS\n\nclass Flickr30kDataset(Dataset):\n    def __init__(self, dataframe, image_path, processor):\n        self.dataframe = dataframe\n        self.image_path = image_path\n        self.processor = processor\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        row = self.dataframe.iloc[idx]\n        image_file = os.path.join(self.image_path, row['image'])\n        image = Image.open(image_file).convert('RGB')\n        caption = row['caption']\n\n        inputs = self.processor(\n            images=image,\n            text=caption,\n            return_tensors=\"pt\",\n            padding=\"max_length\",\n            max_length=30,\n            truncation=True\n        )\n        return {\n            \"pixel_values\": inputs[\"pixel_values\"].squeeze(),\n            \"input_ids\": inputs[\"input_ids\"].squeeze(),\n            \"attention_mask\": inputs[\"attention_mask\"].squeeze()\n        }\n\n\n# 6. INIT PROCESSOR & MODEL\n\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\nmodel = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\nmodel = model.to(DEVICE)\n\n\n# 7. CREATE DATASET & DATALOADER\n\ndataset = Flickr30kDataset(df, IMAGES_PATH, processor)\ndataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=2, pin_memory=True)\n\n\n# 8. TRAINING SETUP\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\nscaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))  # Mixed precision only if GPU\n\nepochs = 1  # Increase for better results\nmodel.train()\n\nfor epoch in range(epochs):\n    loop = tqdm(dataloader, leave=True)\n    for batch in loop:\n        pixel_values = batch[\"pixel_values\"].to(DEVICE)\n        input_ids = batch[\"input_ids\"].to(DEVICE)\n        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n\n        with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n            outputs = model(\n                pixel_values=pixel_values,\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=input_ids\n            )\n            loss = outputs.loss\n\n        optimizer.zero_grad()\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        loop.set_description(f\"Epoch [{epoch+1}/{epochs}]\")\n        loop.set_postfix(loss=loss.item())\n\n\n# 9. SAVE MODEL\n\nmodel.save_pretrained(\"/kaggle/working/blip-flickr30k\")\nprocessor.save_pretrained(\"/kaggle/working/blip-flickr30k\")\n\nprint(\"Model saved!\")\n\n\n# 10. INFERENCE (Caption Generation)\n\nmodel.eval()\ntest_image_path = os.path.join(IMAGES_PATH, df.iloc[0]['image'])\ntest_image = Image.open(test_image_path).convert('RGB')\n\ninputs = processor(images=test_image, return_tensors=\"pt\").to(DEVICE)\n\nwith torch.no_grad():\n    generated_ids = model.generate(**inputs, max_length=30)\n    caption = processor.decode(generated_ids[0], skip_special_tokens=True)\n\nprint(\"Generated Caption:\", caption)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T12:25:47.353843Z","iopub.execute_input":"2025-08-31T12:25:47.354262Z","execution_failed":"2025-08-31T12:44:55.323Z"},"editable":false},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m989.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"2025-08-31 12:27:50.879186: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756643271.255236      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756643271.363519      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Using device: cpu\n","output_type":"stream"},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"name":"stdout","text":"Sample data:\n            image                                            caption\n0  1000092795.jpg   Two young guys with shaggy hair look at their...\n1  1000092795.jpg   Two young , White males are outside near many...\n2  1000092795.jpg   Two men in green shirts are standing in a yard .\n3  1000092795.jpg       A man in a blue shirt standing in a garden .\n4  1000092795.jpg            Two friends enjoy time spent together .\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe8b13f3a7614762a0325b970a10cdf8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/506 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4442f15086e9449fb384faa69134a75b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47fae6b6b0f0449f933c24113314083e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"819206d4a2bf4c03b0d16b7e05fe6224"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa5dbdf7bea24d4886077238c34cea52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1d79c3e5b0b41b9a5ca0cf6a7ed6a91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4dd2788e3494e19ba2caeea3dc0458c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"266b64d148004f2bb1b614ef87903b59"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/432987411.py:88: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))  # Mixed precision only if GPU\n\n  0%|          | 0/19865 [00:00<?, ?it/s]\u001b[A/tmp/ipykernel_36/432987411.py:100: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n\nEpoch [1/1]:   0%|          | 0/19865 [00:43<?, ?it/s]\u001b[A\nEpoch [1/1]:   0%|          | 0/19865 [00:43<?, ?it/s, loss=6.87]\u001b[A\nEpoch [1/1]:   0%|          | 1/19865 [00:43<238:34:55, 43.24s/it, loss=6.87]\u001b[A\nEpoch [1/1]:   0%|          | 1/19865 [01:16<238:34:55, 43.24s/it, loss=6.87]\u001b[A\nEpoch [1/1]:   0%|          | 1/19865 [01:16<238:34:55, 43.24s/it, loss=6.55]\u001b[A\nEpoch [1/1]:   0%|          | 2/19865 [01:16<207:23:23, 37.59s/it, loss=6.55]\u001b[A\nEpoch [1/1]:   0%|          | 2/19865 [01:47<207:23:23, 37.59s/it, loss=6.55]\u001b[A\nEpoch [1/1]:   0%|          | 2/19865 [01:47<207:23:23, 37.59s/it, loss=6.6] \u001b[A\nEpoch [1/1]:   0%|          | 3/19865 [01:47<190:02:55, 34.45s/it, loss=6.6]\u001b[A\nEpoch [1/1]:   0%|          | 3/19865 [02:17<190:02:55, 34.45s/it, loss=6.6]\u001b[A\nEpoch [1/1]:   0%|          | 3/19865 [02:17<190:02:55, 34.45s/it, loss=7.32]\u001b[A\nEpoch [1/1]:   0%|          | 4/19865 [02:17<179:22:00, 32.51s/it, loss=7.32]\u001b[A\nEpoch [1/1]:   0%|          | 4/19865 [02:45<179:22:00, 32.51s/it, loss=7.32]\u001b[A\nEpoch [1/1]:   0%|          | 4/19865 [02:45<179:22:00, 32.51s/it, loss=6.49]\u001b[A\nEpoch [1/1]:   0%|          | 5/19865 [02:45<171:03:44, 31.01s/it, loss=6.49]\u001b[A\nEpoch [1/1]:   0%|          | 5/19865 [03:15<171:03:44, 31.01s/it, loss=6.49]\u001b[A\nEpoch [1/1]:   0%|          | 5/19865 [03:15<171:03:44, 31.01s/it, loss=5.41]\u001b[A\nEpoch [1/1]:   0%|          | 6/19865 [03:15<168:19:14, 30.51s/it, loss=5.41]\u001b[A\nEpoch [1/1]:   0%|          | 6/19865 [03:43<168:19:14, 30.51s/it, loss=5.41]\u001b[A\nEpoch [1/1]:   0%|          | 6/19865 [03:43<168:19:14, 30.51s/it, loss=6.75]\u001b[A\nEpoch [1/1]:   0%|          | 7/19865 [03:43<165:06:05, 29.93s/it, loss=6.75]\u001b[A\nEpoch [1/1]:   0%|          | 7/19865 [04:12<165:06:05, 29.93s/it, loss=6.75]\u001b[A\nEpoch [1/1]:   0%|          | 7/19865 [04:12<165:06:05, 29.93s/it, loss=5.81]\u001b[A\nEpoch [1/1]:   0%|          | 8/19865 [04:12<162:28:28, 29.46s/it, loss=5.81]\u001b[A\nEpoch [1/1]:   0%|          | 8/19865 [04:40<162:28:28, 29.46s/it, loss=5.81]\u001b[A\nEpoch [1/1]:   0%|          | 8/19865 [04:40<162:28:28, 29.46s/it, loss=5.25]\u001b[A\nEpoch [1/1]:   0%|          | 9/19865 [04:40<161:14:55, 29.24s/it, loss=5.25]\u001b[A\nEpoch [1/1]:   0%|          | 9/19865 [05:09<161:14:55, 29.24s/it, loss=5.25]\u001b[A\nEpoch [1/1]:   0%|          | 9/19865 [05:09<161:14:55, 29.24s/it, loss=5.37]\u001b[A\nEpoch [1/1]:   0%|          | 10/19865 [05:09<160:02:04, 29.02s/it, loss=5.37]\u001b[A\nEpoch [1/1]:   0%|          | 10/19865 [05:41<160:02:04, 29.02s/it, loss=5.37]\u001b[A\nEpoch [1/1]:   0%|          | 10/19865 [05:41<160:02:04, 29.02s/it, loss=5.3] \u001b[A\nEpoch [1/1]:   0%|          | 11/19865 [05:41<165:13:33, 29.96s/it, loss=5.3]\u001b[A\nEpoch [1/1]:   0%|          | 11/19865 [06:11<165:13:33, 29.96s/it, loss=5.3]\u001b[A\nEpoch [1/1]:   0%|          | 11/19865 [06:11<165:13:33, 29.96s/it, loss=5.71]\u001b[A\nEpoch [1/1]:   0%|          | 12/19865 [06:11<165:31:29, 30.02s/it, loss=5.71]\u001b[A\nEpoch [1/1]:   0%|          | 12/19865 [06:42<165:31:29, 30.02s/it, loss=5.71]\u001b[A\nEpoch [1/1]:   0%|          | 12/19865 [06:42<165:31:29, 30.02s/it, loss=5.38]\u001b[A\nEpoch [1/1]:   0%|          | 13/19865 [06:42<166:15:19, 30.15s/it, loss=5.38]\u001b[A\nEpoch [1/1]:   0%|          | 13/19865 [07:12<166:15:19, 30.15s/it, loss=5.38]\u001b[A\nEpoch [1/1]:   0%|          | 13/19865 [07:12<166:15:19, 30.15s/it, loss=5.6] \u001b[A\nEpoch [1/1]:   0%|          | 14/19865 [07:12<165:56:26, 30.09s/it, loss=5.6]\u001b[A\nEpoch [1/1]:   0%|          | 14/19865 [07:42<165:56:26, 30.09s/it, loss=5.6]\u001b[A\nEpoch [1/1]:   0%|          | 14/19865 [07:42<165:56:26, 30.09s/it, loss=5.39]\u001b[A\nEpoch [1/1]:   0%|          | 15/19865 [07:42<166:03:00, 30.11s/it, loss=5.39]\u001b[A\nEpoch [1/1]:   0%|          | 15/19865 [08:12<166:03:00, 30.11s/it, loss=5.39]\u001b[A\nEpoch [1/1]:   0%|          | 15/19865 [08:12<166:03:00, 30.11s/it, loss=5.62]\u001b[A\nEpoch [1/1]:   0%|          | 16/19865 [08:12<165:57:38, 30.10s/it, loss=5.62]\u001b[A\nEpoch [1/1]:   0%|          | 16/19865 [08:42<165:57:38, 30.10s/it, loss=5.62]\u001b[A\nEpoch [1/1]:   0%|          | 16/19865 [08:42<165:57:38, 30.10s/it, loss=4.94]\u001b[A\nEpoch [1/1]:   0%|          | 17/19865 [08:42<166:06:31, 30.13s/it, loss=4.94]\u001b[A\nEpoch [1/1]:   0%|          | 17/19865 [09:14<166:06:31, 30.13s/it, loss=4.94]\u001b[A\nEpoch [1/1]:   0%|          | 17/19865 [09:14<166:06:31, 30.13s/it, loss=5.49]\u001b[A\nEpoch [1/1]:   0%|          | 18/19865 [09:14<168:35:38, 30.58s/it, loss=5.49]\u001b[A\nEpoch [1/1]:   0%|          | 18/19865 [09:46<168:35:38, 30.58s/it, loss=5.49]\u001b[A\nEpoch [1/1]:   0%|          | 18/19865 [09:46<168:35:38, 30.58s/it, loss=5.17]\u001b[A\nEpoch [1/1]:   0%|          | 19/19865 [09:46<172:05:55, 31.22s/it, loss=5.17]\u001b[A\nEpoch [1/1]:   0%|          | 19/19865 [10:16<172:05:55, 31.22s/it, loss=5.17]\u001b[A\nEpoch [1/1]:   0%|          | 19/19865 [10:16<172:05:55, 31.22s/it, loss=4.4] \u001b[A\nEpoch [1/1]:   0%|          | 20/19865 [10:16<170:10:05, 30.87s/it, loss=4.4]\u001b[A\nEpoch [1/1]:   0%|          | 20/19865 [10:48<170:10:05, 30.87s/it, loss=4.4]\u001b[A\nEpoch [1/1]:   0%|          | 20/19865 [10:48<170:10:05, 30.87s/it, loss=5.13]\u001b[A\nEpoch [1/1]:   0%|          | 21/19865 [10:48<172:02:51, 31.21s/it, loss=5.13]\u001b[A\nEpoch [1/1]:   0%|          | 21/19865 [11:19<172:02:51, 31.21s/it, loss=5.13]\u001b[A\nEpoch [1/1]:   0%|          | 21/19865 [11:19<172:02:51, 31.21s/it, loss=4.99]\u001b[A\nEpoch [1/1]:   0%|          | 22/19865 [11:19<171:42:44, 31.15s/it, loss=4.99]\u001b[A\nEpoch [1/1]:   0%|          | 22/19865 [11:50<171:42:44, 31.15s/it, loss=4.99]\u001b[A\nEpoch [1/1]:   0%|          | 22/19865 [11:50<171:42:44, 31.15s/it, loss=5.4] \u001b[A\nEpoch [1/1]:   0%|          | 23/19865 [11:50<170:46:45, 30.99s/it, loss=5.4]\u001b[A\nEpoch [1/1]:   0%|          | 23/19865 [12:21<170:46:45, 30.99s/it, loss=5.4]\u001b[A\nEpoch [1/1]:   0%|          | 23/19865 [12:21<170:46:45, 30.99s/it, loss=4.86]\u001b[A\nEpoch [1/1]:   0%|          | 24/19865 [12:21<170:02:35, 30.85s/it, loss=4.86]\u001b[A\nEpoch [1/1]:   0%|          | 24/19865 [12:50<170:02:35, 30.85s/it, loss=4.86]\u001b[A\nEpoch [1/1]:   0%|          | 24/19865 [12:50<170:02:35, 30.85s/it, loss=4.26]\u001b[A\nEpoch [1/1]:   0%|          | 25/19865 [12:50<168:10:39, 30.52s/it, loss=4.26]\u001b[A\nEpoch [1/1]:   0%|          | 25/19865 [13:21<168:10:39, 30.52s/it, loss=4.26]\u001b[A\nEpoch [1/1]:   0%|          | 25/19865 [13:21<168:10:39, 30.52s/it, loss=4.46]\u001b[A\nEpoch [1/1]:   0%|          | 26/19865 [13:21<168:04:49, 30.50s/it, loss=4.46]\u001b[A\nEpoch [1/1]:   0%|          | 26/19865 [13:51<168:04:49, 30.50s/it, loss=4.46]\u001b[A\nEpoch [1/1]:   0%|          | 26/19865 [13:51<168:04:49, 30.50s/it, loss=4.45]\u001b[A\nEpoch [1/1]:   0%|          | 27/19865 [13:51<167:13:18, 30.35s/it, loss=4.45]\u001b[A\nEpoch [1/1]:   0%|          | 27/19865 [14:21<167:13:18, 30.35s/it, loss=4.45]\u001b[A\nEpoch [1/1]:   0%|          | 27/19865 [14:21<167:13:18, 30.35s/it, loss=4.82]\u001b[A\nEpoch [1/1]:   0%|          | 28/19865 [14:21<167:01:23, 30.31s/it, loss=4.82]\u001b[A\nEpoch [1/1]:   0%|          | 28/19865 [14:52<167:01:23, 30.31s/it, loss=4.82]\u001b[A\nEpoch [1/1]:   0%|          | 28/19865 [14:52<167:01:23, 30.31s/it, loss=4.41]\u001b[A\nEpoch [1/1]:   0%|          | 29/19865 [14:52<167:29:54, 30.40s/it, loss=4.41]\u001b[A\nEpoch [1/1]:   0%|          | 29/19865 [15:22<167:29:54, 30.40s/it, loss=4.41]\u001b[A\nEpoch [1/1]:   0%|          | 29/19865 [15:22<167:29:54, 30.40s/it, loss=4.68]\u001b[A\nEpoch [1/1]:   0%|          | 30/19865 [15:22<168:05:56, 30.51s/it, loss=4.68]\u001b[A\nEpoch [1/1]:   0%|          | 30/19865 [15:54<168:05:56, 30.51s/it, loss=4.68]\u001b[A\nEpoch [1/1]:   0%|          | 30/19865 [15:54<168:05:56, 30.51s/it, loss=4.34]\u001b[A\nEpoch [1/1]:   0%|          | 31/19865 [15:54<169:18:52, 30.73s/it, loss=4.34]\u001b[A\nEpoch [1/1]:   0%|          | 31/19865 [16:24<169:18:52, 30.73s/it, loss=4.34]\u001b[A\nEpoch [1/1]:   0%|          | 31/19865 [16:24<169:18:52, 30.73s/it, loss=4.6] \u001b[A\nEpoch [1/1]:   0%|          | 32/19865 [16:24<169:17:00, 30.73s/it, loss=4.6]\u001b[A","output_type":"stream"}],"execution_count":null}]}